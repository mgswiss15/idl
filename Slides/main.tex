\documentclass[aspectratio=169, smaller]{beamer}
\usepackage[]{slidespreamble}
\usepackage[]{math_commands}
\setbeameroption{hide notes}
\mode<presentation>

% presentation title
\title{Introduction to Deep Learning}
\subtitle{Intro}

\begin{document}

\input{intro}

% \begin{frame}
% \layout
% \end{frame}

\begin{frame}[t]{Outline}
\setcounter{framenumber}{1}
\tableofcontents[]
\end{frame}

\section{Measures and probability}
\begin{frame}{Measures - assigning mass to sets}

\structure{Measurable space $(S, \salg)$}
\begin{itemize}
  \item $S$ - set (e.g., $\mR^d$, discrete set, etc.)
  \item $\salg$ - $\sigma$-algebra on $S$ (collection of measurable subsets of $S$)
  \begin{itemize}
    \item closed under complements and countable unions
    \item contains $\emptyset$ and $S$
  \end{itemize}
\end{itemize}

\vskip 1em
\structure{Measure $\mu$ on $(S, \salg)$ - function $\mu: \salg \to [0, \infty]$}
\begin{itemize}
  \item $\mu(\emptyset) = 0$
  \item countable additivity: for disjoint $\{A_i: i \in I\} \subseteq \salg$, $\mu\left( \bigcup_{i \in I} A_i \right) = \sum_{i \in I} \mu(A_i)$
\end{itemize}

\vskip 1em
\structure{Examples:}
\begin{itemize}
\item counting measure: $\#(A) = $ number of elements in $A$
\item Lebesgue measure on $\mR^d$: $\lambda(A) = $ volume of $A$
\end{itemize}

\end{frame}

\note[enumerate]
{
\item $\sigma$-algebra $\salg$ is collection of measurable sets (closed under complements and countable unions)
\item For practical purposes: think of $\salg$ as "all reasonable subsets"
\item Lebesgue measure generalizes notions of length, area, volume
\item Probability measure is just a finite measure normalized to total mass 1
\item This abstraction allows us to talk about probability rigorously, but we'll soon move to more practical objects
}


\end{document}